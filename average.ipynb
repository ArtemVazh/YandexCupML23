{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08682d9d-55f3-4476-a536-e5c232a235e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.remove('/home/jovyan/.imgenv-lm-poly-0/lib/python3.7/site-packages')\n",
    "os.environ['PYTHONPATH'] = '/home/user/conda/envs/ya/lib/python3.10/site-packages'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6990e83d-463d-48e1-ad2b-603931ba7b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_DEV = 0\n",
    "NUM_TAGS = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65de37a1-7301-4888-9c18-33f701e0f589",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc016659-0cbe-465b-bd19-4070edc42f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "tags = [[int(i) for i in x.split(',')] for x in df_train.tags.values]\n",
    "dict_tags = {}\n",
    "for cls_tags in tags:\n",
    "    for c in cls_tags:\n",
    "        if c not in dict_tags.keys():\n",
    "            dict_tags[c] = Counter(cls_tags)\n",
    "        else:\n",
    "            dict_tags[c].update(Counter(cls_tags))\n",
    "            \n",
    "for tag in dict_tags.keys():\n",
    "    del dict_tags[tag][tag]\n",
    "    n = np.sum(list(dict_tags[tag].values()))\n",
    "    for t in dict_tags[tag].keys():\n",
    "        dict_tags[tag][t] = dict_tags[tag][t]/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "736d1fc6-03a0-446f-9cec-d7454fd8c581",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76715/76715 [03:44<00:00, 342.45it/s]\n"
     ]
    }
   ],
   "source": [
    "track_idx2embeds = {}\n",
    "for fn in tqdm(glob('track_embeddings/*')):\n",
    "    name = fn.split('/')[1].split('.')[0]\n",
    "    if name == \"track_embeddings\":\n",
    "        continue\n",
    "    track_idx = int(name)\n",
    "    embeds = np.load(fn)\n",
    "    track_idx2embeds[track_idx] = embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39ec4bb6-ab59-4dc3-9135-9d2c33742551",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaggingDataset(Dataset):\n",
    "    def __init__(self, df, aug=0, testing=False):\n",
    "        self.df = df\n",
    "        self.testing = testing\n",
    "        self.aug = aug\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        track_idx = row.track\n",
    "        embeds = track_idx2embeds[track_idx]\n",
    "        if self.testing:\n",
    "            return track_idx, embeds\n",
    "        tags = [int(x) for x in row.tags.split(',')]\n",
    "        target = np.zeros(NUM_TAGS)\n",
    "        target[tags] = 1\n",
    "        \n",
    "        if np.random.choice([0, 1], p=[1 - self.aug, self.aug]):\n",
    "            s = np.random.uniform(0.0, 0.4)\n",
    "            e = np.random.uniform(s+0.1, 1)\n",
    "            s = int(s * embeds.shape[0])\n",
    "            e = int(e * embeds.shape[0])\n",
    "            embeds = embeds[s:e]\n",
    "        \n",
    "        return track_idx, embeds, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2517243c-0f9f-41d7-ac28-274be934adc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TaggingDataset(df_train[:-1000], aug=0.6)\n",
    "val_dataset = TaggingDataset(df_train[-1000:])\n",
    "\n",
    "test_dataset = TaggingDataset(df_test, testing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "507bd164-0b50-4cb7-b792-dc223d5204bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, emb_dim=768, mult=4, p=0.0):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(emb_dim, emb_dim * mult),\n",
    "            nn.Dropout(p),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(emb_dim * mult, emb_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "    \n",
    "class AttentionPooling(nn.Module):\n",
    "    def __init__(self, embedding_size):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Sequential(\n",
    "            nn.Linear(embedding_size, embedding_size),\n",
    "            nn.LayerNorm(embedding_size),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(embedding_size, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        attn_logits = self.attn(x)\n",
    "        if mask is not None:\n",
    "            attn_logits[mask] = -float('inf')\n",
    "        attn_weights = torch.softmax(attn_logits, dim=1)\n",
    "        x = x * attn_weights\n",
    "        x = x.sum(dim=1)\n",
    "        return x\n",
    "    \n",
    "class Network(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes = NUM_TAGS,\n",
    "        input_dim = 768,\n",
    "        hidden_dim = 512\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.position_enc = nn.Embedding(128, input_dim, padding_idx=-1) \n",
    "        self.proj = FeedForward(input_dim)\n",
    "        self.bn = nn.BatchNorm1d(input_dim)\n",
    "        self.ln = nn.LayerNorm(input_dim)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=768, nhead=12, activation=\"gelu\", batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=6)\n",
    "        self.poooling = AttentionPooling(input_dim)\n",
    "        self.fc = nn.Linear(input_dim, num_classes)\n",
    "               \n",
    "    def forward(self, embeds):\n",
    "        embeds = self.proj(embeds)\n",
    "        src_key_padding_mask = (embeds.mean(-1) == -1)\n",
    "        embeds = self.ln(embeds)\n",
    "        x = self.transformer_encoder(embeds, src_key_padding_mask=src_key_padding_mask)\n",
    "        x = self.bn(self.poooling(x, mask=src_key_padding_mask))\n",
    "        outs = self.fc(x)\n",
    "        return outs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "483de899-40a4-419a-881b-e631ffb6acf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def train_epoch(model, loader, criterion, optimizer, scheduler, print_loss=True, iteration_step=100, epoch=0):\n",
    "    model.train()\n",
    "    running_loss = None\n",
    "    alpha = 0.8\n",
    "    iters = len(loader)\n",
    "    for iteration,data in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "        track_idxs, embeds, target = data\n",
    "        embeds = [x.to(CUDA_DEV) for x in embeds]\n",
    "        embeds = pad_sequence(embeds, padding_value=-1, batch_first=True)[:, :64, :]\n",
    "        target = target.to(CUDA_DEV)\n",
    "        pred_logits = model(embeds)\n",
    "        pred_probs = torch.sigmoid(pred_logits)\n",
    "        ce_loss = criterion(pred_logits, target)\n",
    "            \n",
    "        ce_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "        optimizer.step()\n",
    "        scheduler.step(epoch + iteration / iters)\n",
    "        \n",
    "        if running_loss is None:\n",
    "            running_loss = ce_loss.item()\n",
    "        else:\n",
    "            running_loss = alpha * running_loss + (1 - alpha) * ce_loss.item()\n",
    "        if (iteration % iteration_step == 0) and print_loss:\n",
    "            print('   {} batch {} running loss {} loss {}'.format(\n",
    "                datetime.now(), iteration + 1, running_loss, ce_loss.item()\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b98a2b7d-0b2d-4903-9493-82c169a5b273",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, loader):\n",
    "    model.eval()\n",
    "    track_idxs = []\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            track_idx, embeds = data\n",
    "            embeds = [x.to(CUDA_DEV) for x in embeds]\n",
    "            embeds = pad_sequence(embeds, padding_value=-1, batch_first=True)[:, :64, :]\n",
    "            pred_logits = model(embeds)\n",
    "            pred_probs = torch.sigmoid(pred_logits)\n",
    "            predictions.append(pred_probs.cpu().numpy())\n",
    "            track_idxs.append(track_idx.numpy())\n",
    "    predictions = np.vstack(predictions)\n",
    "    track_idxs = np.vstack(track_idxs).ravel()\n",
    "    return track_idxs, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ea0cabe-ff37-46db-9a09-1bde4b1112c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def predict_train(model, loader):\n",
    "    model.eval()\n",
    "    track_idxs = []\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            track_idx, embeds, target = data\n",
    "            embeds = [x.to(CUDA_DEV) for x in embeds]\n",
    "            embeds = pad_sequence(embeds, padding_value=-1, batch_first=True)[:, :64, :]\n",
    "            pred_logits = model(embeds)\n",
    "            pred_probs = torch.sigmoid(pred_logits)\n",
    "            predictions.append(pred_probs.cpu().numpy())\n",
    "            track_idxs.append(track_idx.numpy())\n",
    "            targets.append(target.numpy())\n",
    "    predictions = np.vstack(predictions)\n",
    "    targets = np.vstack(targets)\n",
    "    track_idxs = np.vstack(track_idxs).ravel()\n",
    "    return track_idxs, predictions, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a242fb4-c9bc-478f-9566-510c5f81b822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(b):\n",
    "    track_idxs = torch.from_numpy(np.vstack([x[0] for x in b]))\n",
    "    embeds = [torch.from_numpy(x[1]) for x in b]\n",
    "    targets = np.vstack([x[2] for x in b])\n",
    "    targets = torch.from_numpy(targets)\n",
    "    return track_idxs, embeds, targets\n",
    "\n",
    "def collate_fn_test(b):\n",
    "    track_idxs = torch.from_numpy(np.vstack([x[0] for x in b]))\n",
    "    embeds = [torch.from_numpy(x[1]) for x in b]\n",
    "    return track_idxs, embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97919be4-2dfb-433c-a601-5b2fe175974e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=128, shuffle=False, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=False, collate_fn=collate_fn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bec3919f-97fc-4fb0-950c-8ea852cfb886",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/conda/envs/ya/lib/python3.10/site-packages/torch/nn/modules/transformer.py:287: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at ../aten/src/ATen/NestedTensorImpl.cpp:177.)\n",
      "  output = torch._nested_tensor_from_mask(output, src_key_padding_mask.logical_not(), mask_check=False)\n"
     ]
    }
   ],
   "source": [
    "model = Network().cuda()\n",
    "track_idxs, predictions = predict(model, test_dataloader)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b307e26b-bd0c-476b-9d7d-009275a2b787",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_all = [\"./workdir/final_es/12_6_0.6_80_64_10_50_3e-05_1e-05_10_1e-07_394529034/prediction_last_mean_folds.csv\",\n",
    "          \"./workdir/final_es/12_6_0.6_80_64_10_50_3e-05_1e-05_10_1e-07_7777/prediction_last_mean_folds.csv\",\n",
    "          \"./workdir/final/12_6_0.6_80_64_10_50_3e-05_1e-05_10_1e-07_9/prediction_last_mean_folds.csv\",\n",
    "          \"./workdir/final/12_6_0.6_80_64_10_50_3e-05_1e-05_10_1e-07_928431908/prediction_last_mean_folds.csv\",\n",
    "             \n",
    "          \"./workdir/final/12_6_0.6_80_64_10_50_3e-05_1e-05_10_1e-07_12312049/prediction_last_mean_folds.csv\",\n",
    "          \"./workdir/final/12_6_0.6_80_64_10_50_3e-05_1e-05_10_1e-07_3490394039/prediction_last_mean_folds.csv\",\n",
    "          \"./workdir/final_es/12_6_0.6_80_64_10_50_3e-05_1e-05_10_1e-07_42/prediction_last_mean_folds.csv\",\n",
    "          \"./workdir/final_es/12_6_0.6_80_64_10_50_3e-05_1e-05_10_1e-07_12323/prediction_last_mean_folds.csv\",\n",
    "             \n",
    "          \"./workdir/12_6_0.6_64_64_10_100_3e-05_1e-05_10_1e-07_123/prediction_mean_folds.csv\", \n",
    "          \"./workdir/12_6_0.6_64_64_10_100_3e-05_1e-05_10_1e-07_777/prediction_mean_folds.csv\",\n",
    "          \"./workdir/12_6_0.6_64_64_10_100_3e-05_1e-05_10_1e-07_99999/prediction_mean_folds.csv\",\n",
    "          \"./workdir/12_6_0.6_80_64_10_100_3e-05_1e-05_10_1e-07_394529034/prediction_mean_folds.csv\",\n",
    "          \"./workdir/12_6_0.6_80_64_10_100_3e-05_1e-05_10_1e-07_123/prediction_mean_folds.csv\",\n",
    "          \"./workdir/ls/12_6_0.6_80_64_10_100_3e-05_1e-05_10_1e-07_123/prediction_mean_folds.csv\",\n",
    "          \"./workdir/12_6_0.6_80_64_10_100_3e-05_1e-05_10_1e-07_777/prediction_mean_folds.csv\",\n",
    "          \"./workdir/12_6_0.6_80_64_10_100_3e-05_1e-05_10_1e-07_1231238/prediction_mean_folds.csv\",\n",
    "          \"./workdir/12_6_0.6_80_64_10_100_3e-05_1e-05_10_1e-07_12323/prediction_mean_folds.csv\",\n",
    "          \"./workdir/12_6_0.6_80_64_10_100_3e-05_1e-05_10_1e-07_99999/prediction_mean_folds.csv\",\n",
    "         ]\n",
    "preds = []\n",
    "for i, path in enumerate(paths_all):\n",
    "    df = pd.read_csv(path)\n",
    "    preds.append(np.array([[float(a) for a in x.split(',')] for x in df.prediction.values]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a29bcadf-4cca-4a81-8c9f-912fa3844a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "368e6401-d49f-496c-a46d-c39ee003722e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.mean(preds, axis=0).astype(np.float32)\n",
    "\n",
    "for i, c in enumerate(predictions.argmax(-1)):\n",
    "    probs = np.array([1 + dict_tags[c].get(t, 0) for t in np.arange(predictions.shape[1])])\n",
    "    probs[c] = 2\n",
    "    predictions[i] = predictions[i] * probs\n",
    "    predictions[i] /= predictions[i].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54cbd527-8e5d-408c-b225-4056d0cee70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame([\n",
    "    {'track': track, 'prediction': ','.join([str(p) for p in probs])}\n",
    "    for track, probs in zip(track_idxs, predictions)\n",
    "])\n",
    "predictions_df.to_csv(f'./workdir/prediction_average_total_mean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95566fbe-73db-4ced-907a-155240954d2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b1fa52-e167-4394-910f-0b45d2013722",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09b2d69-7890-4232-98a2-04a5d23ff0a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ya",
   "language": "python",
   "name": "ya"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
